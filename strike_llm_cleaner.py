#!/usr/bin/env python3
"""
Strike LLM Cleaner

This script processes JSON files generated by raw_strike_description_collector.py
and uses OpenAI API to extract structured strike data from the newspaper content.

Usage: python strike_llm_cleaner.py <input_folder> <output_folder>
"""

import json
import os
import sys
import re
from pathlib import Path
from typing import List, Dict, Optional
from datetime import datetime
import openai
from openai import OpenAI

# Configuration - Modify these as needed
OPENAI_MODEL = "gpt-4o"  # You can change this to "gpt-3.5-turbo" or other models
MAX_RETRIES = 3
RETRY_DELAY = 1  # seconds

def setup_openai_client() -> OpenAI:
    """Initialize OpenAI client with API key from environment variable."""
    api_key = os.environ.get('OPENAI_API_KEY')
    if not api_key:
        print("âŒ Error: OPENAI_API_KEY environment variable not set")
        print("   Please set it with: set OPENAI_API_KEY=your_api_key_here")
        sys.exit(1)
    
    return OpenAI(api_key=api_key)


def extract_year_from_filename(filename: str) -> Optional[str]:
    """Extract year from filename like 'toke_munka_Nepszava_1903_05__pages51-96_images_page_36.json'."""
    # Pattern: toke_munka_Nepszava_YYYY_
    match = re.search(r'toke_munka_Nepszava_(\d{4})_', filename)
    if match:
        return match.group(1)
    
    print(f"    âš ï¸  Could not extract year from filename: {filename}")
    return None


def query_openai_with_retry(client: OpenAI, messages: List[Dict], max_retries: int = MAX_RETRIES) -> Optional[str]:
    """Query OpenAI API with retry logic."""
    import time
    
    for attempt in range(max_retries):
        try:
            response = client.chat.completions.create(
                model=OPENAI_MODEL,
                messages=messages,
                temperature=0.1,  # Low temperature for consistent results
                max_tokens=4000
            )
            return response.choices[0].message.content.strip()
        
        except Exception as e:
            print(f"    âš ï¸  OpenAI API error (attempt {attempt + 1}/{max_retries}): {e}")
            if attempt < max_retries - 1:
                time.sleep(RETRY_DELAY * (attempt + 1))  # Exponential backoff
            else:
                print(f"    âŒ Failed to get response after {max_retries} attempts")
                return None
    
    return None


def extract_date_from_header(client: OpenAI, newspaper_header: str, year: str) -> str:
    """Extract date information from newspaper header using OpenAI."""
    if newspaper_header == "Unknown Issue":
        return year
    
    print(f"    ğŸ—“ï¸  Extracting date from header: {newspaper_header[:50]}...")
    
    messages = [
        {
            "role": "system",
            "content": "You are extracting date information from Hungarian newspaper headers. Return only two numbers: month and day, separated by a space. If you cannot determine the exact date, return 'UNKNOWN'."
        },
        {
            "role": "user",
            "content": f"Extract the month (1-12) and day (1-31) from this Hungarian newspaper header: '{newspaper_header}'. Return only two numbers separated by a space, nothing else."
        }
    ]
    
    response = query_openai_with_retry(client, messages)
    if not response:
        return year
    
    # Parse the response
    try:
        if response.upper() == 'UNKNOWN':
            return year
        
        parts = response.strip().split()
        if len(parts) == 2 and parts[0].isdigit() and parts[1].isdigit():
            month = int(parts[0])
            day = int(parts[1])
            
            # Validate date ranges
            if 1 <= month <= 12 and 1 <= day <= 31:
                # Create ISO 8601 date
                iso_date = f"{year}-{month:02d}-{day:02d}"
                print(f"    âœ… Extracted date: {iso_date}")
                return iso_date
    
    except (ValueError, IndexError):
        pass
    
    print(f"    âš ï¸  Could not parse date from response: {response}")
    return year


def extract_strikes_from_content(client: OpenAI, column_content: str) -> List[Dict]:
    """Extract structured strike data from column content using OpenAI."""
    print(f"    ğŸ“Š Analyzing content for strikes ({len(column_content)} characters)...")
    
    strike_prompt = """I am sending you a text from the "NÃ‰PSZAVA" labor journal from the early 20th century. Please read and digest it. Please check if there were strikes. If there were strikes, return a list of them as structured JSON elements, with the following informations/elements.
1) "event_date" - exact date in ISO 8601 format
2) "industry_txt" - which industry participated (in plain words)
3) "industry_SIC" - industry SIC code, if possible
4) "participants_txt" - who were the participants (in plain words)
5) "participants_ISCO" - participant ISCO code, if possible
6) "firm_name" - which is the firm where the strike happens, or whose estate (if it is an agricultural strike)
7) "location_txt" - which is the location of the strike â€“ as described there
8) "location_official" - current official name of the closest settlement
9) "location_geonames_id" - GeoNames ID of the closest settlement 
10) "strike_status" - is the strike planned/ongoing/resolved
11) "description_en" - at most 30 word description of the event in English

Don't write any scripts, just read it. Don't write any accompanying texts like 'here is the data you asked for' just send the plain data."""
    
    messages = [
        {
            "role": "system",
            "content": "You are analyzing Hungarian labor newspaper content from the early 20th century to extract strike information. Return only valid JSON arrays with strike data, or an empty array if no strikes are found."
        },
        {
            "role": "user",
            "content": f"{strike_prompt}\n\nText to analyze:\n{column_content}"
        }
    ]
    
    response = query_openai_with_retry(client, messages)
    if not response:
        return []
    
    # Try to parse JSON response
    try:
        # Clean the response - remove any markdown formatting
        clean_response = response.strip()
        if clean_response.startswith('```json'):
            clean_response = clean_response[7:]
        if clean_response.endswith('```'):
            clean_response = clean_response[:-3]
        clean_response = clean_response.strip()
        
        # Parse JSON
        strikes_data = json.loads(clean_response)
        
        # Ensure it's a list
        if isinstance(strikes_data, dict):
            strikes_data = [strikes_data]
        elif not isinstance(strikes_data, list):
            print(f"    âš ï¸  Unexpected response format: {type(strikes_data)}")
            return []
        
        print(f"    âœ… Found {len(strikes_data)} strike(s)")
        return strikes_data
    
    except json.JSONDecodeError as e:
        print(f"    âŒ Failed to parse JSON response: {e}")
        print(f"    ğŸ“ Response was: {response[:200]}...")
        return []


def generate_output_filename(input_filename: str) -> str:
    """Generate output filename based on input filename."""
    # Replace .json with _strikes.json
    if input_filename.lower().endswith('.json'):
        base_name = input_filename[:-5]  # Remove .json
    else:
        base_name = input_filename
    
    return f"{base_name}_strikes.json"


def process_file(client: OpenAI, input_path: str, output_path: str, input_folder: str) -> bool:
    """Process a single JSON file and extract strike data."""
    filename = os.path.basename(input_path)
    print(f"    ğŸ“„ Processing: {filename}")
    
    try:
        # Load input data
        with open(input_path, 'r', encoding='utf-8') as f:
            input_data = json.load(f)
        
        # Extract year from filename
        year = extract_year_from_filename(filename)
        if not year:
            print(f"    âŒ Skipping file - could not extract year")
            return False
        
        # Extract required fields
        newspaper_header = input_data.get("newspaper_header", "Unknown Issue")
        column_content = input_data.get("column_content", "")
        
        if not column_content.strip():
            print(f"    âŒ Skipping file - no column content")
            return False
        
        # Extract publication date
        publication_date = extract_date_from_header(client, newspaper_header, year)
        
        # Extract strikes from content
        strikes = extract_strikes_from_content(client, column_content)
        
        # Prepare output data
        output_data = {
            "publication_date": publication_date,
            "newspaper_header": newspaper_header,
            "column_content": column_content,
            "source_file": os.path.relpath(input_path, input_folder),
            "strikes": strikes,
            "processing_info": {
                "extracted_year": year,
                "total_strikes_found": len(strikes),
                "processed_at": datetime.now().isoformat(),
                "openai_model_used": OPENAI_MODEL
            }
        }
        
        # Save output
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, indent=2, ensure_ascii=False)
        
        print(f"    âœ… Saved {len(strikes)} strike(s) to: {os.path.basename(output_path)}")
        return True
    
    except Exception as e:
        print(f"    âŒ Error processing {filename}: {e}")
        return False


def main():
    if len(sys.argv) != 3:
        print("Usage: python strike_llm_cleaner.py <input_folder> <output_folder>")
        print("\nThis script processes JSON files from raw_strike_description_collector.py")
        print("and uses OpenAI API to extract structured strike data.")
        print("\nRequirements:")
        print("- OPENAI_API_KEY environment variable must be set")
        print("- Input folder should contain JSON files from the collector script")
        print("\nFeatures:")
        print("- Extracts publication dates from newspaper headers")
        print("- Identifies and structures strike information")
        print("- Generates detailed JSON output with metadata")
        sys.exit(1)
    
    input_folder = sys.argv[1]
    output_folder = sys.argv[2]
    
    # Validate input
    if not os.path.exists(input_folder):
        print(f"âŒ Input folder not found: {input_folder}")
        sys.exit(1)
    
    # Create output directory
    os.makedirs(output_folder, exist_ok=True)
    
    print("ğŸš€ Starting Strike LLM Cleaner...")
    print(f"ğŸ“ Input folder: {input_folder}")
    print(f"ğŸ“ Output folder: {output_folder}")
    print(f"ğŸ¤– OpenAI model: {OPENAI_MODEL}")
    
    # Setup OpenAI client
    try:
        client = setup_openai_client()
        print("âœ… OpenAI client initialized")
    except Exception as e:
        print(f"âŒ Failed to initialize OpenAI client: {e}")
        sys.exit(1)
    
    # Find all JSON files in input folder
    json_files = []
    for root, dirs, files in os.walk(input_folder):
        for file in files:
            if file.lower().endswith('.json'):
                json_files.append(os.path.join(root, file))
    
    if not json_files:
        print("âŒ No JSON files found in input folder!")
        sys.exit(1)
    
    # Sort files for consistent processing
    json_files.sort()
    
    # Process all files
    print(f"\nğŸ“‹ Processing {len(json_files)} JSON files...")
    processed_count = 0
    total_strikes = 0
    
    for i, input_path in enumerate(json_files):
        print(f"\n[{i+1}/{len(json_files)}] " + "="*60)
        
        # Generate output path
        input_filename = os.path.basename(input_path)
        output_filename = generate_output_filename(input_filename)
        output_path = os.path.join(output_folder, output_filename)
        
        # Process the file
        if process_file(client, input_path, output_path, input_folder):
            processed_count += 1
            
            # Count strikes in output file
            try:
                with open(output_path, 'r', encoding='utf-8') as f:
                    output_data = json.load(f)
                total_strikes += len(output_data.get("strikes", []))
            except:
                pass
    
    # Final summary
    print(f"\n{'='*80}")
    print(f"ğŸ‰ Processing complete!")
    print(f"âœ… Successfully processed: {processed_count}/{len(json_files)} files")
    print(f"ğŸ“Š Total strikes extracted: {total_strikes}")
    print(f"ğŸ“ Output files saved to: {output_folder}")
    
    if processed_count == 0:
        print("âš ï¸  No files were successfully processed.")
        print("   Check the input files and OpenAI API configuration.")


if __name__ == "__main__":
    main()